{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "[U-Net](https://www.nature.com/articles/s41592-018-0261-2) is a convolutional neural network for semantic segmentation of images. This implementation of U-Net, optimized for binary segmentation of biological microscopy images and movies, gives users a high-level interface to (i) augment training data, (ii) train with various loss functions and (iii) predict large tif-files.   \n",
    "\n",
    "If you need help using a function, you can always try running `help(whichever_interesting_function)` or just look at the source code. If you need help using a class (one that is directly under the `biu.unet` director), trying to understand the examples in this notebook probably will be more helpful than finding the documentation of that function.\n",
    "\n",
    "IMPORTANT: Two packages that depend on your hardware need to be installed manually before running bio-image-unet. Convolutional neural networks run much faster on Nvidia-GPUs than on CPUs. To enable training and prediction on GPUs, users need to install [CUDA toolkit](https://developer.nvidia.com/cuda-toolkit) and the corresponding version of PyTorch from [the official PyTorch website](https://pytorch.org/get-started/locally/). Select the correct distribution of CUDA on this webpage and run the command in your terminal. bio-image-unet doesn't depend on a specific version of CUDA and has been tested with PyTorch 1.7.0+.\n",
    "\n",
    "To install `bio-image-unet` from [PyPI](https://pypi.org/project/bio-image-unet/), execute  `pip install bio-image-unet` in your terminal. Finally, to import the U-Net package, write `import biu.unet as unet`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training data generation and augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataProcess` class creates a PyTorch `Dataset` object. Paths of directories with training data and labels as well as parameters for data processing and data augmentation are all specified upon initialization function, see below.\n",
    "\n",
    "Training images and labels need to have the following folder structure (images and labels with exactly identical names in separate folders):\n",
    "\n",
    "```\n",
    "path/to/training/data/\n",
    "|\n",
    "├── image\n",
    "│   ├── 1.tif\n",
    "│   ├── 2.tif\n",
    "│   ├── 3.tif\n",
    "│   ├── 4.tif\n",
    "│   ├── image3.tif\n",
    "│   ├── whatever_name42.tif\n",
    "│   ├── 5.tif\n",
    "│   ├── ...\n",
    "│   ├── ...\n",
    "└── label\n",
    "    ├── 1.tif\n",
    "    ├── 2.tif\n",
    "    ├── 3.tif\n",
    "    ├── 4.tif\n",
    "    ├── image3.tif\n",
    "    ├── whatever_name42.tif\n",
    "    ├── 5.tif\n",
    "    ├── ...\n",
    "    ├── ...\n",
    "```\n",
    "\n",
    "The `DataProcess` class creates a data set when initialized. It takes the following parameters as arguments:\n",
    "\n",
    "```\n",
    "Create training data object for network training\n",
    "\n",
    "1) Create folder structure for training data\n",
    "2) Move and preprocess training images\n",
    "3) Split input images into tiles\n",
    "4) Augment training data\n",
    "5) Create object of PyTorch Dataset class for training\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "source_dir : Tuple[str, str]\n",
    "    Path of training data [images, labels]. Images need to be tif files.\n",
    "dim_out : Tuple[int, int]\n",
    "    Resize dimensions of images for training\n",
    "aug_factor : int\n",
    "    Factor of image augmentation\n",
    "data_path : str\n",
    "    Base path of directories for training data\n",
    "dilate_mask\n",
    "    Radius of binary dilation of masks [-2, -1, 0, 1, 2]\n",
    "dilate_kernel : str\n",
    "    Dilation kernel ('disk' or 'square')\n",
    "val_split : float\n",
    "    Validation split for training\n",
    "invert : bool\n",
    "    If True, greyscale binary labels is inverted\n",
    "skeletonize : bool\n",
    "    If True, binary labels are skeletonized\n",
    "create : bool, optional\n",
    "    If False, existing data set in data_path is used\n",
    "clip_threshold : Tuple[float, float]\n",
    "    Clip thresholds for intensity normalization of images\n",
    "shiftscalerotate : [float, float, float]\n",
    "    Shift, scale and rotate image during augmentation\n",
    "noise_amp : float\n",
    "    Amplitude of Gaussian noise for image augmentation\n",
    "brightness_contrast : Tuple[float, float]\n",
    "    Adapt brightness and contrast of images during augmentation\n",
    "rescale : float, optional\n",
    "    Rescale all images and labels by factor rescale\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bio-image-unet package\n",
    "import biu.unet as unet\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files found\n",
      "Number of training images: 0\n"
     ]
    }
   ],
   "source": [
    "# path to training data\n",
    "dir_images = 'E:/path/to/images/'\n",
    "dir_masks = 'E:/path/to/labels'\n",
    "\n",
    "# path to directory for training data generation (is created automatically, drive should have enough storage)\n",
    "data_path = './data/'\n",
    "\n",
    "# generation of training data set\n",
    "dataset = unet.DataProcess([dir_images, dir_masks], data_path=data_path, create=True, dilate_mask=2, skeletonize=False, \n",
    "                            noise_amp=10, brightness_contrast=(0.15, 0.15), aug_factor=10, invert=True, clip_threshold=(0., 99.8), \n",
    "                            dim_out=(256, 256), shiftscalerotate=(0, 0, 0), rescale=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The `Trainer` class is for training U-Net. When initialized, following training parameters are specified (see below). When the object is successfully created, the training is started with `trainer.start()`. \n",
    "\n",
    "```\n",
    "Class for training of neural network. Creates trainer object, training is started with .start().\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "dataset\n",
    "    Training data, object of PyTorch Dataset class\n",
    "num_epochs : int\n",
    "    Number of training epochs\n",
    "network\n",
    "    Network class (Default Unet)\n",
    "batch_size : int\n",
    "    Batch size for training\n",
    "lr : float\n",
    "    Learning rate\n",
    "n_filter : int\n",
    "    Number of convolutional filters in first layer\n",
    "val_split : float\n",
    "    Validation split\n",
    "save_dir : str\n",
    "    Path of directory to save trained networks\n",
    "save_name : str\n",
    "    Base name for saving trained networks\n",
    "save_iter : bool\n",
    "    If True, network state is save after each epoch\n",
    "load_weights : str, optional\n",
    "    If not None, network state is loaded before training\n",
    "loss : str\n",
    "    Loss function ('BCEDice', 'Tversky' or 'logcoshTversky')\n",
    "loss_params : Tuple[float, float]\n",
    "    Parameter of loss function, depends on chosen loss function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model\n",
    "model = unet.Unet\n",
    "# create trainer\n",
    "trainer = unet.Trainer(dataset, num_epochs=100, network=model, batch_size=10, lr=0.0001, n_filter=32, val_split=0.2, \n",
    "             save_dir='./', save_name='model.pt', save_iter=False, load_weights=False, loss_function='BCEDice', loss_params=(0.5, 0.5))\n",
    "\n",
    "# test data\n",
    "test_data_path =  'E:/path/of/test/data/'\n",
    "result_path = 'E:/path/of/test/data/results/'\n",
    "os.makedirs(result_path, exist_ok=True)  # create result_path\n",
    "             \n",
    "# start training\n",
    "trainer.start(test_data_path=test_data_path, result_path=result_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction of data\n",
    "\n",
    "The `Prediction` class predicts single images and movies with U-Net. Prediction is started upon initialization. The initialization method has following arguments: \n",
    "````\n",
    "Prediction of tif files with standard 2D U-Net\n",
    "\n",
    "1) Loading file and preprocess (normalization)\n",
    "2) Resizing of images into patches with resize_dim\n",
    "3) Prediction with U-Net\n",
    "4) Stitching of predicted patches and averaging of overlapping regions\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "imgs : ndarray/str\n",
    "    numpy array of images or path of tif file\n",
    "result_name : str\n",
    "    path for result\n",
    "model_params : str\n",
    "    path of u-net parameters (.pt file)\n",
    "network\n",
    "    Network class (Default: U-Net)\n",
    "resize_dim\n",
    "    Image dimensions for resizing for prediction\n",
    "invert : bool\n",
    "    Invert greyscale of image(s) before prediction\n",
    "clip_threshold : Tuple[float, float]\n",
    "    Clip threshold for image intensity before prediction\n",
    "add_tile : int, optional\n",
    "    Add additional tiles for splitting large images to increase overlap\n",
    "normalize_result : bool\n",
    "    If true, results are normalized to [0, 255]\n",
    "progress_notifier:\n",
    "    Wrapper to show tqdm progress notifier in gui\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# predict tif file\n",
    "tif_file = '/path/of/tif/file.tif'\n",
    "result_name = '/path/of/result/tif/file.tif'\n",
    "model_params = '/path/of/U-Net/model/params.pt'\n",
    "prediction = unet.Predict(tif_file, result_name, network=unet.Unet, model_params=model_params, invert=False, \n",
    "                          resize_dim=(1024, 1024), clip_threshold=(0., 99.8))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
