{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# \"Vanilla\" U-Net Quickstart\n",
    "\n",
    "*Yuxi Long*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Introduction\n",
    "\n",
    "U-Net is a neural network structure that has shown great results in biomedical image segmentation. See [this paper](https://www.nature.com/articles/s41592-018-0261-2). This repository contains an implementation of this network. An alternate version of U-Net, the Siamese U-Net, is also included in this package and its documentation can be found at [using_siam_unet.ipynb](https://github.com/danihae/bio-image-unet/blob/master/biu/using_siam_unet.ipynb).\n",
    "\n",
    "If you need help using a function, you can always try running `help(whichever_interesting_function)` or just look at the source code. If you need help using a class (one that is directly under the `biu.unet` directory), trying to understand the examples in this notebook probably will be more helpful than finding the documentation of that function.\n",
    "\n",
    "IMPORTANT: Two packages that depend on your hardware need to be installed manually before running biu. To install CUDA 11.1 which is officially supported by PyTorch, navigate to [its installation page](https://developer.nvidia.com/cuda-11.1.1-download-archive) and follow the instructions onscreen. Because PyTorch depends on your CUDA installation version, it will need to be installed manually as well, through [the official PyTorch website](https://pytorch.org/get-started/locally/). Select the correct distribution of CUDA on this webpage and run the command in your terminal. biu doesn't depend on a specific version of CUDA and has been tested with PyTorch 1.7.0+.\n",
    "\n",
    "Finally, to import the U-Net package, write `import biu.unet as unet`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Basics of U-Net\n",
    "\n",
    "U-Net takes in one frame as input and tries to predict the labels as its output. Theoretically, the labels can be whatever you want -- it can be a certain type of tissue, or it can be cell boundaries.\n",
    "\n",
    "To train the U-Net, we need to first do the work of drawing the cell boundaries (or any other kind of label you want) ourselves, so the machine can learn how to draw the cell boundaries given the frames. Example training data can be found at <https://filedn.eu/lKfS794F9UgX7PDuBQcfChB/DeepTissue/>. \n",
    "\n",
    "You can use any drawing software to create the training data. We have found [Autodesk Sketchbook](https://www.autodesk.com/products/sketchbook/overview) or [GIMP](https://www.gimp.org/) to be quite useful. Just make sure to use a tablet with stylus and turn on a podcast while you draw. To create the training data, we first isolate the frame we want either using `biu.helpers.extract_frame_of_movie`, or use gimp or whatever magical tool you have. Open the image in your drawing software, decrease its opacity, add another layer on top of the image, and start drawing your labels (what you want the network to predict). You are encouraged to use the pen tool with color black and radius 1 in your drawing software.\n",
    "\n",
    "After you have finished drawing labels of the entire image, remove (or make invisible) the image layer, and you are just left with the label layer. Export your label, convert it to grayscale using any tool you can find (we have found <https://online-photo-converter.com/black-and-white-image> to be handy), name it the same as the image, and move on to the next frame you wish to create a label for. You don't need to create a label for every frame, but theoretically the more frames you have, the better your neural network will learn. Always feel free to train the network and see what output you get even if you don't think you have enough labels.\n",
    "\n",
    "Once you are done creating labels, move on to the next step."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Data preparation\n",
    "\n",
    "For the \"vanilla\" U-Net, this step is simple."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "When you are done converting your labels to grayscale, organize the labels and images in a way similar to this shown. An example can be found in `training_data.zip`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "```\n",
    "training_data/lateral_epidermis\n",
    "├── yokogawa\n",
    "│   ├── image\n",
    "│   │   ├── 1.tif\n",
    "│   │   ├── 2.tif\n",
    "│   │   ├── 3.tif\n",
    "│   │   ├── 5.tif\n",
    "│   │   ├── 7.tif\n",
    "│   │   └── 83.tif\n",
    "│   └── label\n",
    "│       ├── 1.tif\n",
    "│       ├── 2.tif\n",
    "│       ├── 3.tif\n",
    "│       ├── 5.tif\n",
    "│       ├── 7.tif\n",
    "│       └── 83.tif\n",
    "\n",
    "```"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training is simple. For example:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from biu.unet import *\n",
    "\n",
    "dataset = 'lateral_epidermis/yokogawa' # example using sample dataset\n",
    "base_dir = './' \n",
    "\n",
    "# path to training data (images and labels with identical names in separate folders)\n",
    "dir_images = f'{base_dir}/training_data/{dataset}/image/'\n",
    "dir_masks = f'{base_dir}/training_data/{dataset}/label/'\n",
    "\n",
    "print('starting to create training dataset')\n",
    "# create training data set\n",
    "data = DataProcess([dir_images, dir_masks], data_path='./data', dilate_mask=0, aug_factor=10, create=False, invert=False, clip_thres=(0.2, 99.8), dim_out=(256, 256), shiftscalerotate=(0, 0, 0))\n",
    "\n",
    "save_dir = f'{base_dir}/models/yokogawa_lateral_epidermis'\n",
    "# create trainer\n",
    "training = Trainer(data ,num_epochs=500 ,batch_size=12, load_weights=False, lr=0.0001, n_filter=32, save_iter=True, save_dir=save_dir)\n",
    "\n",
    "training.start()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note here that the value of the `n_filter` parameter is set to `32`. The network won't break with a different value of this, but you need to use the same value for the Predict part."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Predict"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Predicting is simple as well. Just swap in the parameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load package\n",
    "from biu.unet import *\n",
    "import os\n",
    "os.nice(10)\n",
    "from  biu.siam_unet.helpers import tif_to_mp4\n",
    "\n",
    "base_dir = './'\n",
    "out_dir = f'{base_dir}/predicted_out'\n",
    "model = f'{base_dir}/models/yokogawa_lateral_epidermis/model_epoch_100.pth'\n",
    "\n",
    "tif_file = f'{base_dir}/training_data/test_data/new_microscope/21C04_shgGFP_kin_2_Pos4.tif'\n",
    "\n",
    "result_file = f'{out_dir}/siam_bce_amnio_100_epochs_21C04_shgGFP_kin_2_Pos4.tif'\n",
    "out_mp4_file = result_file[:-4] + '.mp4'\n",
    "\n",
    "print('starting to predict file')\n",
    "# predict file \n",
    "predict = Predict(tif_file, result_file, model, invert=False, resize_dim=(512, 512), n_filter=32)\n",
    "# convert to mp4\n",
    "tif_to_mp4.convert_to_mp4(result_file, output_file=out_mp4_file, normalize_to_0_255=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Appendix: An annotated structure of the siam_unet package"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below is an annotated structure of the siam_unet package. Use `help(function)` to read the docstring of each function for a better understanding.\n",
    "\n",
    "```\n",
    "Package                                         Use\n",
    "\n",
    ".\n",
    "├── __init__.py\n",
    "├── data.py                                     dataloader script\n",
    "├── siam_unet.py                                Siam U-Net model\n",
    "├── train.py                                    training script\n",
    "├── losses.py                                   loss functions\n",
    "├── predict.py                                  prediction script\n",
    "├── helpers                                     helper functions (usually not \n",
    "                                                        so useful except the \n",
    "                                                        ones mentioned in this notebook)\n",
    "                                                        \n",
    "│   ├── average_tifs.py                             averages a list of tiff files\n",
    "│   ├── create_pixel_value_histogram.py             creates histograms for the \n",
    "                                                        pixel values in tif \n",
    "                                                        files. Useful for \n",
    "                                                        debugging during training\n",
    "│   ├── cuda_test.py                                tests cuda functionality\n",
    "│   ├── extract_frame_of_movie.py                   extract a certain frame of a \n",
    "                                                        tif movie \n",
    "│   ├── find_frame_of_image.py                      finds the frame number of \n",
    "                                                        a given query image \n",
    "                                                        within search_space.\n",
    "│   ├── generate_plain_image.py                     generates a plain image\n",
    "│   ├── generate_siam_unet_input_imgs.py            generates a coupled image \n",
    "                                                        for Siam U-Net training\n",
    "│   ├── low_mem_tif_utils.py                        utilities for handling tif \n",
    "                                                        files with low memory \n",
    "                                                        usage\n",
    "│   ├── threshold_images.py                         thresholds each frame of a \n",
    "                                                        tif movie\n",
    "│   ├── tif_to_mp4.py                               uses ffmpeg to convert a tif \n",
    "                                                        movie to mp4\n",
    "│   └── util.py                                     various utilities. see docstring\n",
    "\n",
    "```"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}